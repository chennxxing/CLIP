{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:23.015761722Z",
     "start_time": "2023-10-26T10:23:21.325650870Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPModel\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from cifar import Cifar_train, Cifar_test, Cifar_test_normal\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_clip =  CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model_clip = model_clip.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:24.817646191Z",
     "start_time": "2023-10-26T10:23:23.077478761Z"
    }
   },
   "id": "d67ba325aeeeb061"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "dataset = Cifar_train()\n",
    "dataset_loader = cycle(torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False, num_workers=0, drop_last=True\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:25.644660300Z",
     "start_time": "2023-10-26T10:23:25.634612695Z"
    }
   },
   "id": "2bcd0864332eb50"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "###### dataset\n",
    "\n",
    "#new = next(dataset_loader)\n",
    "#a = model_clip.get_image_features(pixel_values = new.cuda()).float()\n",
    "#a = torch.hstack((a,a))\n",
    "#a = a.reshape((32, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:28.186247688Z",
     "start_time": "2023-10-26T10:23:28.179496211Z"
    }
   },
   "id": "87f68b409e21aff5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from matplotlib import animation\n",
    "from torchvision import transforms\n",
    "from ddpm.GaussianDiffusion import GaussianDiffusionModel, get_beta_schedule\n",
    "import ddpm.dataset\n",
    "from ddpm.helpers import gridify_output, load_parameters\n",
    "from ddpm.UNet import UNetModel, update_ema_params\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import collections\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:30.568303513Z",
     "start_time": "2023-10-26T10:23:30.476575941Z"
    }
   },
   "id": "1d011f0cc2769944"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ROOT_DIR = \"./try/\"\n",
    "\n",
    "def save(final, unet, optimiser, args, ema, loss=0, epoch=0):\n",
    "    \"\"\"\n",
    "    Save model final or checkpoint\n",
    "    :param final: bool for final vs checkpoint\n",
    "    :param unet: unet instance\n",
    "    :param optimiser: ADAM optim\n",
    "    :param args: model parameters\n",
    "    :param ema: ema instance\n",
    "    :param loss: loss for checkpoint\n",
    "    :param epoch: epoch for checkpoint\n",
    "    :return: saved model\n",
    "    \"\"\"\n",
    "    if final:\n",
    "        torch.save(\n",
    "                {\n",
    "                    'n_epoch':              args[\"EPOCHS\"],\n",
    "                    'model_state_dict':     unet.state_dict(),\n",
    "                    'optimizer_state_dict': optimiser.state_dict(),\n",
    "                    \"ema\":                  ema.state_dict(),\n",
    "                    \"args\":                 args\n",
    "                    # 'loss': LOSS,\n",
    "                    }, ROOT_DIR+'params-final.pt'\n",
    "                )\n",
    "    else:\n",
    "        torch.save(\n",
    "                {\n",
    "                    'n_epoch':              epoch,\n",
    "                    'model_state_dict':     unet.state_dict(),\n",
    "                    'optimizer_state_dict': optimiser.state_dict(),\n",
    "                    \"args\":                 args,\n",
    "                    \"ema\":                  ema.state_dict(),\n",
    "                    'loss':                 loss,\n",
    "                    }, ROOT_DIR+'diff_epoch='+str(epoch)+'.pt'\n",
    "                )\n",
    "        \n",
    "        \n",
    "def training_outputs(diffusion, x, est, noisy, epoch, row_size, ema, args, save_imgs=False, save_vids=False):\n",
    "    \"\"\"\n",
    "    Saves video & images based on args info\n",
    "    :param diffusion: diffusion model instance\n",
    "    :param x: x_0 real data value\n",
    "    :param est: estimate of the noise at x_t (output of the model)\n",
    "    :param noisy: x_t\n",
    "    :param epoch:\n",
    "    :param row_size: rows for outputs into torchvision.utils.make_grid\n",
    "    :param ema: exponential moving average unet for sampling\n",
    "    :param save_imgs: bool for saving imgs\n",
    "    :param save_vids: bool for saving diffusion videos\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(ROOT_DIR+'diffusion-videos/ARGS='+args[\"arg_num\"])\n",
    "        os.makedirs(ROOT_DIR+'diffusion-training-images/ARGS='+args[\"arg_num\"])\n",
    "    except OSError:\n",
    "        pass\n",
    "    if save_imgs:\n",
    "        if epoch % 100 == 0:\n",
    "            # for a given t, output x_0, & prediction of x_(t-1), and x_0\n",
    "            noise = torch.rand_like(x)\n",
    "            t = torch.randint(0, diffusion.num_timesteps, (x.shape[0],), device=x.device)\n",
    "            x_t = diffusion.sample_q(x, t, noise)\n",
    "            temp = diffusion.sample_p(ema, x_t, t)\n",
    "            out = torch.cat(\n",
    "                    (x[:row_size, ...].cpu(), temp[\"sample\"][:row_size, ...].cpu(),\n",
    "                     temp[\"pred_x_0\"][:row_size, ...].cpu())\n",
    "                    )\n",
    "            plt.title(f'real,sample,prediction x_0-{epoch}epoch')\n",
    "        else:\n",
    "            # for a given t, output x_0, x_t, & prediction of noise in x_t & MSE\n",
    "            out = torch.cat(\n",
    "                    (x[:row_size, ...].cpu(), noisy[:row_size, ...].cpu(), est[:row_size, ...].cpu(),\n",
    "                     (est - noisy).square().cpu()[:row_size, ...])\n",
    "                    )\n",
    "            plt.title(f'real,noisy,noise prediction,mse-{epoch}epoch')\n",
    "        plt.rcParams['figure.dpi'] = 150\n",
    "        plt.grid(False)\n",
    "        plt.imshow(gridify_output(out, row_size), cmap='gray')\n",
    "\n",
    "        plt.savefig(ROOT_DIR+'diffusion-training-images/ARGS='+args[\"arg_num\"]+'/EPOCH='+str(epoch)+'.png')\n",
    "        plt.clf()\n",
    "\n",
    "    plt.close('all')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:32.625833499Z",
     "start_time": "2023-10-26T10:23:32.605721529Z"
    }
   },
   "id": "37354cfc4fb27969"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "f = open('args103.json')\n",
    "args = json.load(f)\n",
    "f.close()\n",
    "args[\"arg_num\"] = \"103\"\n",
    "\n",
    "\n",
    "in_channels = 1\n",
    "model = UNetModel(\n",
    "            args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n",
    "                \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "            in_channels=in_channels\n",
    "            )\n",
    "\n",
    "betas = get_beta_schedule(args['T'], args['beta_schedule'])\n",
    "\n",
    "diffusion = GaussianDiffusionModel(\n",
    "        args['img_size'], betas, loss_weight=args['loss_weight'],\n",
    "        loss_type=args['loss-type'], noise=args[\"noise_fn\"], img_channels=in_channels\n",
    "        )\n",
    "\n",
    "start_epoch = 0\n",
    "ema = copy.deepcopy(model)\n",
    "\n",
    "tqdm_epoch = range(start_epoch, args['EPOCHS'] + 1)\n",
    "model.to(device)\n",
    "ema.to(device)\n",
    "optimiser = optim.AdamW(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'], betas=(0.9, 0.999))\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "vlb = collections.deque([], maxlen=10)\n",
    "iters = range(600 // args['Batch_Size']) if args[\"dataset\"].lower() != \"cifar\" else range(600)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:37.256108839Z",
     "start_time": "2023-10-26T10:23:37.061250036Z"
    }
   },
   "id": "2948c2f5de8f9a6b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxing/anaconda3/envs/CLIP/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, most recent total VLB: 357.7779541015625 mean total VLB: 357.7780, prior vlb: 0.00, vb: 0.36, x_0_mse: 0.76, mse: 2.81 time elapsed 0:00, est time remaining: 2:36\r\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "epoch: 200, most recent total VLB: 370.6346435546875 mean total VLB: 364.2063, prior vlb: 0.00, vb: 0.37, x_0_mse: 0.33, mse: 2.80 time elapsed 0:23, est time remaining: 1:32\r\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "epoch: 400, most recent total VLB: 373.12060546875 mean total VLB: 367.1777, prior vlb: 0.00, vb: 0.37, x_0_mse: 0.25, mse: 2.82 time elapsed 0:45, est time remaining: 1:07\r\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "epoch: 600, most recent total VLB: 369.6062316894531 mean total VLB: 367.7849, prior vlb: 0.00, vb: 0.37, x_0_mse: 0.30, mse: 2.79 time elapsed 1:08, est time remaining: 0:45\r\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "epoch: 800, most recent total VLB: 377.09271240234375 mean total VLB: 369.6464, prior vlb: 0.00, vb: 0.38, x_0_mse: 0.25, mse: 2.84 time elapsed 1:30, est time remaining: 0:22\r\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "epoch: 1000, most recent total VLB: 400.29351806640625 mean total VLB: 374.7543, prior vlb: 0.00, vb: 0.40, x_0_mse: 0.24, mse: 3.01 time elapsed 1:52, est time remaining: 0:00\r\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_epoch:\n",
    "    mean_loss = []\n",
    "    print(epoch)\n",
    "    for i in iters:\n",
    "        #print(i)\n",
    "        data = next(dataset_loader)\n",
    "        a = model_clip.get_image_features(pixel_values = data.cuda()).float()\n",
    "        a = torch.hstack((a,a))\n",
    "        x = a.reshape((-1, 1, 32, 32))\n",
    "\n",
    "\n",
    "\n",
    "        loss, estimates = diffusion.p_loss(model, x, args)\n",
    "\n",
    "        noisy, est = estimates[1], estimates[2]\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimiser.step()\n",
    "\n",
    "        update_ema_params(ema, model)\n",
    "        mean_loss.append(loss.data.cpu())\n",
    "\n",
    "        if epoch % 150 == 0 and i == 0:\n",
    "            row_size = min(8, args['Batch_Size'])\n",
    "            training_outputs(\n",
    "                    diffusion, x, est, noisy, epoch, row_size, save_imgs=args['save_imgs'],\n",
    "                    save_vids=args['save_vids'], ema=ema, args=args\n",
    "                    )\n",
    "\n",
    "    losses.append(np.mean(mean_loss))\n",
    "    if epoch % 200 == 0:\n",
    "        time_taken = time.time() - start_time\n",
    "        remaining_epochs = args['EPOCHS'] - epoch\n",
    "        time_per_epoch = time_taken / (epoch + 1 - start_epoch)\n",
    "        hours = remaining_epochs * time_per_epoch / 3600\n",
    "        mins = (hours % 1) * 60\n",
    "        hours = int(hours)\n",
    "\n",
    "        vlb_terms = diffusion.calc_total_vlb(x, model, args)\n",
    "        vlb.append(vlb_terms[\"total_vlb\"].mean(dim=-1).cpu().item())\n",
    "        print(\n",
    "                f\"epoch: {epoch}, most recent total VLB: {vlb[-1]} mean total VLB:\"\n",
    "                f\" {np.mean(vlb):.4f}, \"\n",
    "                f\"prior vlb: {vlb_terms['prior_vlb'].mean(dim=-1).cpu().item():.2f}, vb: \"\n",
    "                f\"{torch.mean(vlb_terms['vb'], dim=list(range(2))).cpu().item():.2f}, x_0_mse: \"\n",
    "                f\"{torch.mean(vlb_terms['x_0_mse'], dim=list(range(2))).cpu().item():.2f}, mse: \"\n",
    "                f\"{torch.mean(vlb_terms['mse'], dim=list(range(2))).cpu().item():.2f}\"\n",
    "                f\" time elapsed {int(time_taken / 3600)}:{((time_taken / 3600) % 1) * 60:02.0f}, \"\n",
    "                f\"est time remaining: {hours}:{mins:02.0f}\\r\"\n",
    "                )\n",
    "    if epoch % 100 == 0 and epoch >= 0:\n",
    "        save(unet=model, args=args, optimiser=optimiser, final=False, ema=ema, epoch=epoch)\n",
    "\n",
    "save(unet=model, args=args, optimiser=optimiser, final=True, ema=ema)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T08:32:39.628928265Z",
     "start_time": "2023-10-26T06:40:26.511560652Z"
    }
   },
   "id": "628afa5c5f2738e8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "####### test\n",
    "output = torch.load(\"./try/cifar10/0_normal/params-final.pt\", map_location=device)\n",
    "\n",
    "unet = UNetModel(\n",
    "            args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], in_channels=in_channels\n",
    "            )\n",
    "\n",
    "betas = get_beta_schedule(args['T'], args['beta_schedule'])\n",
    "\n",
    "diff = GaussianDiffusionModel(\n",
    "        args['img_size'], betas, loss_weight=args['loss_weight'],\n",
    "        loss_type=args['loss-type'], noise=args[\"noise_fn\"], img_channels=in_channels\n",
    "        )\n",
    "\n",
    "unet.load_state_dict(output[\"ema\"])\n",
    "unet.to(device)\n",
    "unet.eval()\n",
    "\n",
    "\n",
    "dataset_test = Cifar_test_normal()\n",
    "dataset_loader_test = cycle(torch.utils.data.DataLoader(\n",
    "            dataset_test,\n",
    "            batch_size=1,\n",
    "            shuffle=False, num_workers=0, drop_last=True))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:23:44.405271305Z",
     "start_time": "2023-10-26T10:23:44.135280478Z"
    }
   },
   "id": "71964b7a1555b6b4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxing/anaconda3/envs/CLIP/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, rows @ epoch: 1\n",
      "[0.5672905]\n",
      "epoch 1, rows @ epoch: 1\n",
      "[0.55058825]\n",
      "epoch 2, rows @ epoch: 1\n",
      "[0.5843264]\n",
      "epoch 3, rows @ epoch: 1\n",
      "[0.55015916]\n",
      "epoch 4, rows @ epoch: 1\n",
      "[0.56276006]\n",
      "epoch 5, rows @ epoch: 1\n",
      "[0.61035514]\n",
      "epoch 6, rows @ epoch: 1\n",
      "[0.5855142]\n",
      "epoch 7, rows @ epoch: 1\n",
      "[0.57535]\n",
      "epoch 8, rows @ epoch: 1\n",
      "[0.55190974]\n",
      "epoch 9, rows @ epoch: 1\n",
      "[0.56203324]\n",
      "epoch 10, rows @ epoch: 1\n",
      "[0.58880323]\n",
      "epoch 11, rows @ epoch: 1\n",
      "[0.5907398]\n",
      "epoch 12, rows @ epoch: 1\n",
      "[0.5944265]\n",
      "epoch 13, rows @ epoch: 1\n",
      "[0.5791825]\n",
      "epoch 14, rows @ epoch: 1\n",
      "[0.5234366]\n",
      "epoch 15, rows @ epoch: 1\n",
      "[0.5670816]\n",
      "epoch 16, rows @ epoch: 1\n",
      "[0.5061038]\n",
      "epoch 17, rows @ epoch: 1\n",
      "[0.58089995]\n",
      "epoch 18, rows @ epoch: 1\n",
      "[0.5781916]\n",
      "epoch 19, rows @ epoch: 1\n",
      "[0.56592596]\n",
      "epoch 20, rows @ epoch: 1\n",
      "[0.57095647]\n",
      "epoch 21, rows @ epoch: 1\n",
      "[0.5874123]\n",
      "epoch 22, rows @ epoch: 1\n",
      "[0.5898467]\n",
      "epoch 23, rows @ epoch: 1\n",
      "[0.5772633]\n",
      "epoch 24, rows @ epoch: 1\n",
      "[0.5379525]\n",
      "epoch 25, rows @ epoch: 1\n",
      "[0.5179456]\n",
      "epoch 26, rows @ epoch: 1\n",
      "[0.57590413]\n",
      "epoch 27, rows @ epoch: 1\n",
      "[0.52221733]\n",
      "epoch 28, rows @ epoch: 1\n",
      "[0.50710094]\n",
      "epoch 29, rows @ epoch: 1\n",
      "[0.616222]\n",
      "epoch 30, rows @ epoch: 1\n",
      "[0.54524267]\n",
      "epoch 31, rows @ epoch: 1\n",
      "[0.58600485]\n",
      "epoch 32, rows @ epoch: 1\n",
      "[0.5870652]\n",
      "epoch 33, rows @ epoch: 1\n",
      "[0.5738791]\n",
      "epoch 34, rows @ epoch: 1\n",
      "[0.5893457]\n",
      "epoch 35, rows @ epoch: 1\n",
      "[0.5900664]\n",
      "epoch 36, rows @ epoch: 1\n",
      "[0.5624907]\n",
      "epoch 37, rows @ epoch: 1\n",
      "[0.5762151]\n",
      "epoch 38, rows @ epoch: 1\n",
      "[0.5672238]\n",
      "epoch 39, rows @ epoch: 1\n",
      "[0.57301295]\n",
      "epoch 40, rows @ epoch: 1\n",
      "[0.56839526]\n",
      "epoch 41, rows @ epoch: 1\n",
      "[0.51333666]\n",
      "epoch 42, rows @ epoch: 1\n",
      "[0.5844778]\n",
      "epoch 43, rows @ epoch: 1\n",
      "[0.60275525]\n",
      "epoch 44, rows @ epoch: 1\n",
      "[0.5679319]\n",
      "epoch 45, rows @ epoch: 1\n",
      "[0.5903331]\n",
      "epoch 46, rows @ epoch: 1\n",
      "[0.59793633]\n",
      "epoch 47, rows @ epoch: 1\n",
      "[0.5939132]\n",
      "epoch 48, rows @ epoch: 1\n",
      "[0.5450744]\n",
      "epoch 49, rows @ epoch: 1\n",
      "[0.57069564]\n",
      "epoch 50, rows @ epoch: 1\n",
      "[0.5024572]\n",
      "epoch 51, rows @ epoch: 1\n",
      "[0.5936584]\n",
      "epoch 52, rows @ epoch: 1\n",
      "[0.57583934]\n",
      "epoch 53, rows @ epoch: 1\n",
      "[0.55073905]\n",
      "epoch 54, rows @ epoch: 1\n",
      "[0.5946574]\n",
      "epoch 55, rows @ epoch: 1\n",
      "[0.5949342]\n",
      "epoch 56, rows @ epoch: 1\n",
      "[0.60925364]\n",
      "epoch 57, rows @ epoch: 1\n",
      "[0.57871807]\n",
      "epoch 58, rows @ epoch: 1\n",
      "[0.5868801]\n",
      "epoch 59, rows @ epoch: 1\n",
      "[0.57738626]\n",
      "epoch 60, rows @ epoch: 1\n",
      "[0.5465385]\n",
      "epoch 61, rows @ epoch: 1\n",
      "[0.5649685]\n",
      "epoch 62, rows @ epoch: 1\n",
      "[0.56243134]\n",
      "epoch 63, rows @ epoch: 1\n",
      "[0.56001997]\n",
      "epoch 64, rows @ epoch: 1\n",
      "[0.57985055]\n",
      "epoch 65, rows @ epoch: 1\n",
      "[0.5591001]\n",
      "epoch 66, rows @ epoch: 1\n",
      "[0.5723218]\n",
      "epoch 67, rows @ epoch: 1\n",
      "[0.5771885]\n",
      "epoch 68, rows @ epoch: 1\n",
      "[0.5738882]\n",
      "epoch 69, rows @ epoch: 1\n",
      "[0.571519]\n",
      "epoch 70, rows @ epoch: 1\n",
      "[0.5436317]\n",
      "epoch 71, rows @ epoch: 1\n",
      "[0.5371957]\n",
      "epoch 72, rows @ epoch: 1\n",
      "[0.5806611]\n",
      "epoch 73, rows @ epoch: 1\n",
      "[0.6031384]\n",
      "epoch 74, rows @ epoch: 1\n",
      "[0.5497625]\n",
      "epoch 75, rows @ epoch: 1\n",
      "[0.5709187]\n",
      "epoch 76, rows @ epoch: 1\n",
      "[0.5890997]\n",
      "epoch 77, rows @ epoch: 1\n",
      "[0.5674492]\n",
      "epoch 78, rows @ epoch: 1\n",
      "[0.5839764]\n",
      "epoch 79, rows @ epoch: 1\n",
      "[0.60183156]\n",
      "epoch 80, rows @ epoch: 1\n",
      "[0.5835943]\n",
      "epoch 81, rows @ epoch: 1\n",
      "[0.51509964]\n",
      "epoch 82, rows @ epoch: 1\n",
      "[0.55776495]\n",
      "epoch 83, rows @ epoch: 1\n",
      "[0.59487534]\n",
      "epoch 84, rows @ epoch: 1\n",
      "[0.5451486]\n",
      "epoch 85, rows @ epoch: 1\n",
      "[0.5942828]\n",
      "epoch 86, rows @ epoch: 1\n",
      "[0.5800478]\n",
      "epoch 87, rows @ epoch: 1\n",
      "[0.5955837]\n",
      "epoch 88, rows @ epoch: 1\n",
      "[0.5874661]\n",
      "epoch 89, rows @ epoch: 1\n",
      "[0.56579447]\n",
      "epoch 90, rows @ epoch: 1\n",
      "[0.60984653]\n",
      "epoch 91, rows @ epoch: 1\n",
      "[0.5392411]\n",
      "epoch 92, rows @ epoch: 1\n",
      "[0.5682712]\n",
      "epoch 93, rows @ epoch: 1\n",
      "[0.569071]\n",
      "epoch 94, rows @ epoch: 1\n",
      "[0.5889771]\n",
      "epoch 95, rows @ epoch: 1\n",
      "[0.548628]\n",
      "epoch 96, rows @ epoch: 1\n",
      "[0.57849205]\n",
      "epoch 97, rows @ epoch: 1\n",
      "[0.57583654]\n",
      "epoch 98, rows @ epoch: 1\n",
      "[0.54873407]\n",
      "epoch 99, rows @ epoch: 1\n",
      "[0.58454305]\n",
      "epoch 100, rows @ epoch: 1\n",
      "[0.55128086]\n",
      "epoch 101, rows @ epoch: 1\n",
      "[0.51945716]\n",
      "epoch 102, rows @ epoch: 1\n",
      "[0.5588386]\n",
      "epoch 103, rows @ epoch: 1\n",
      "[0.6100576]\n",
      "epoch 104, rows @ epoch: 1\n",
      "[0.5553226]\n",
      "epoch 105, rows @ epoch: 1\n",
      "[0.5786968]\n",
      "epoch 106, rows @ epoch: 1\n",
      "[0.54728234]\n",
      "epoch 107, rows @ epoch: 1\n",
      "[0.5534365]\n",
      "epoch 108, rows @ epoch: 1\n",
      "[0.59136015]\n",
      "epoch 109, rows @ epoch: 1\n",
      "[0.5392394]\n",
      "epoch 110, rows @ epoch: 1\n",
      "[0.59040964]\n",
      "epoch 111, rows @ epoch: 1\n",
      "[0.5973165]\n",
      "epoch 112, rows @ epoch: 1\n",
      "[0.5672043]\n",
      "epoch 113, rows @ epoch: 1\n",
      "[0.61411154]\n",
      "epoch 114, rows @ epoch: 1\n",
      "[0.5430879]\n",
      "epoch 115, rows @ epoch: 1\n",
      "[0.5823505]\n",
      "epoch 116, rows @ epoch: 1\n",
      "[0.5494013]\n",
      "epoch 117, rows @ epoch: 1\n",
      "[0.564489]\n",
      "epoch 118, rows @ epoch: 1\n",
      "[0.584476]\n",
      "epoch 119, rows @ epoch: 1\n",
      "[0.5825412]\n",
      "epoch 120, rows @ epoch: 1\n",
      "[0.58464897]\n",
      "epoch 121, rows @ epoch: 1\n",
      "[0.56693184]\n",
      "epoch 122, rows @ epoch: 1\n",
      "[0.5557239]\n",
      "epoch 123, rows @ epoch: 1\n",
      "[0.57827526]\n",
      "epoch 124, rows @ epoch: 1\n",
      "[0.5365273]\n",
      "epoch 125, rows @ epoch: 1\n",
      "[0.57958984]\n",
      "epoch 126, rows @ epoch: 1\n",
      "[0.59928644]\n",
      "epoch 127, rows @ epoch: 1\n",
      "[0.5880352]\n"
     ]
    }
   ],
   "source": [
    "data = next(dataset_loader_test)\n",
    "a = model_clip.get_image_features(pixel_values = data.cuda()).float()\n",
    "a = torch.hstack((a,a))\n",
    "x = a.reshape((-1, 1, 32, 32))\n",
    "countnum = 0\n",
    "test_normal_result = []\n",
    "\n",
    "for i in range(128):\n",
    "\n",
    "    predictions = []\n",
    "    sequences = []\n",
    "    mse_thresholds = []\n",
    "\n",
    "    rows, t_distance = 1, 200\n",
    "\n",
    "    threshold = 0.5\n",
    "    print(f\"epoch {i}, rows @ epoch: {rows}\")\n",
    "    for k in range(rows):\n",
    "        countnum += 1\n",
    "        new = next(dataset_loader)\n",
    "        a = model_clip.get_image_features(pixel_values = data.cuda()).float()\n",
    "        a = torch.hstack((a,a))\n",
    "        img = a.reshape((-1, 1, 32, 32))\n",
    "    \n",
    "\n",
    "        #filename = DATASET_PATH + 'final-outputs/ARGS=' + str(args[\"arg_num\"]) + '/abnormal_check/'\n",
    "\n",
    "        output = diff.forward_backward(\n",
    "                unet, img,\n",
    "                see_whole_sequence=\"half\",\n",
    "                # t_distance=5, denoise_fn=args[\"noise_fn\"]\n",
    "                t_distance=t_distance, denoise_fn=args[\"noise_fn\"]\n",
    "                )\n",
    "\n",
    "        loss, estimates = diff.p_loss(unet, img, args, test_t_value = t_distance)\n",
    "        noisy, est = estimates[1], estimates[2]\n",
    "        '''\n",
    "        if new[1].to(device) == 0:\n",
    "            list_norm.append((est - noisy).square()[:1, ...].sum().detach().cpu().numpy())\n",
    "        else:\n",
    "            list_abnorm.append((est - noisy).square()[:1, ...].sum().detach().cpu().numpy())\n",
    "        '''\n",
    "\n",
    "        #output_images = torch.cat((img, output[-1].to(device)))\n",
    "        cos = torch.nn.CosineSimilarity()\n",
    "        result = cos(img.reshape(1,-1), output[-1].reshape(1,-1))\n",
    "        #predictions.append(\n",
    "        #        output_images\n",
    "        #        )\n",
    "        test_normal_result.append(result.cpu().detach().numpy())\n",
    "        print(result.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:28:35.659981177Z",
     "start_time": "2023-10-26T10:23:46.011152295Z"
    }
   },
   "id": "fc82d383aa2ec140"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#### test abnormal\n",
    "output = torch.load(\"./try/cifar10/0_normal/params-final.pt\", map_location=device)\n",
    "\n",
    "unet = UNetModel(\n",
    "            args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], in_channels=in_channels\n",
    "            )\n",
    "\n",
    "betas = get_beta_schedule(args['T'], args['beta_schedule'])\n",
    "\n",
    "diff = GaussianDiffusionModel(\n",
    "        args['img_size'], betas, loss_weight=args['loss_weight'],\n",
    "        loss_type=args['loss-type'], noise=args[\"noise_fn\"], img_channels=in_channels\n",
    "        )\n",
    "\n",
    "unet.load_state_dict(output[\"ema\"])\n",
    "unet.to(device)\n",
    "unet.eval()\n",
    "\n",
    "\n",
    "dataset_test = Cifar_test()\n",
    "dataset_loader_test = cycle(torch.utils.data.DataLoader(\n",
    "            dataset_test,\n",
    "            batch_size=1,\n",
    "            shuffle=False, num_workers=0, drop_last=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:28:57.805544596Z",
     "start_time": "2023-10-26T10:28:57.559478711Z"
    }
   },
   "id": "e4c97306d1f70763"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, rows @ epoch: 1\n",
      "[0.49712548]\n",
      "epoch 1, rows @ epoch: 1\n",
      "[0.5120114]\n",
      "epoch 2, rows @ epoch: 1\n",
      "[0.51548076]\n",
      "epoch 3, rows @ epoch: 1\n",
      "[0.50845635]\n",
      "epoch 4, rows @ epoch: 1\n",
      "[0.4812498]\n",
      "epoch 5, rows @ epoch: 1\n",
      "[0.5118185]\n",
      "epoch 6, rows @ epoch: 1\n",
      "[0.5110575]\n",
      "epoch 7, rows @ epoch: 1\n",
      "[0.5085664]\n",
      "epoch 8, rows @ epoch: 1\n",
      "[0.5109083]\n",
      "epoch 9, rows @ epoch: 1\n",
      "[0.5007997]\n",
      "epoch 10, rows @ epoch: 1\n",
      "[0.4979499]\n",
      "epoch 11, rows @ epoch: 1\n",
      "[0.50092316]\n",
      "epoch 12, rows @ epoch: 1\n",
      "[0.472675]\n",
      "epoch 13, rows @ epoch: 1\n",
      "[0.50972396]\n",
      "epoch 14, rows @ epoch: 1\n",
      "[0.5160289]\n",
      "epoch 15, rows @ epoch: 1\n",
      "[0.49969333]\n",
      "epoch 16, rows @ epoch: 1\n",
      "[0.49910542]\n",
      "epoch 17, rows @ epoch: 1\n",
      "[0.51314795]\n",
      "epoch 18, rows @ epoch: 1\n",
      "[0.4883404]\n",
      "epoch 19, rows @ epoch: 1\n",
      "[0.4909652]\n",
      "epoch 20, rows @ epoch: 1\n",
      "[0.50866973]\n",
      "epoch 21, rows @ epoch: 1\n",
      "[0.5144168]\n",
      "epoch 22, rows @ epoch: 1\n",
      "[0.48969695]\n",
      "epoch 23, rows @ epoch: 1\n",
      "[0.49736267]\n",
      "epoch 24, rows @ epoch: 1\n",
      "[0.50173736]\n",
      "epoch 25, rows @ epoch: 1\n",
      "[0.47809178]\n",
      "epoch 26, rows @ epoch: 1\n",
      "[0.5110618]\n",
      "epoch 27, rows @ epoch: 1\n",
      "[0.5362674]\n",
      "epoch 28, rows @ epoch: 1\n",
      "[0.5130236]\n",
      "epoch 29, rows @ epoch: 1\n",
      "[0.46462727]\n",
      "epoch 30, rows @ epoch: 1\n",
      "[0.5000459]\n",
      "epoch 31, rows @ epoch: 1\n",
      "[0.51411706]\n",
      "epoch 32, rows @ epoch: 1\n",
      "[0.5127125]\n",
      "epoch 33, rows @ epoch: 1\n",
      "[0.49532413]\n",
      "epoch 34, rows @ epoch: 1\n",
      "[0.50597024]\n",
      "epoch 35, rows @ epoch: 1\n",
      "[0.46528167]\n",
      "epoch 36, rows @ epoch: 1\n",
      "[0.5140039]\n",
      "epoch 37, rows @ epoch: 1\n",
      "[0.48221114]\n",
      "epoch 38, rows @ epoch: 1\n",
      "[0.48943806]\n",
      "epoch 39, rows @ epoch: 1\n",
      "[0.49854642]\n",
      "epoch 40, rows @ epoch: 1\n",
      "[0.49358985]\n",
      "epoch 41, rows @ epoch: 1\n",
      "[0.48433536]\n",
      "epoch 42, rows @ epoch: 1\n",
      "[0.5270679]\n",
      "epoch 43, rows @ epoch: 1\n",
      "[0.5069175]\n",
      "epoch 44, rows @ epoch: 1\n",
      "[0.5205126]\n",
      "epoch 45, rows @ epoch: 1\n",
      "[0.51479185]\n",
      "epoch 46, rows @ epoch: 1\n",
      "[0.4820617]\n",
      "epoch 47, rows @ epoch: 1\n",
      "[0.5062126]\n",
      "epoch 48, rows @ epoch: 1\n",
      "[0.5034405]\n",
      "epoch 49, rows @ epoch: 1\n",
      "[0.5164423]\n",
      "epoch 50, rows @ epoch: 1\n",
      "[0.49624515]\n",
      "epoch 51, rows @ epoch: 1\n",
      "[0.51176447]\n",
      "epoch 52, rows @ epoch: 1\n",
      "[0.48316544]\n",
      "epoch 53, rows @ epoch: 1\n",
      "[0.49933583]\n",
      "epoch 54, rows @ epoch: 1\n",
      "[0.502012]\n",
      "epoch 55, rows @ epoch: 1\n",
      "[0.4837759]\n",
      "epoch 56, rows @ epoch: 1\n",
      "[0.5274527]\n",
      "epoch 57, rows @ epoch: 1\n",
      "[0.51243484]\n",
      "epoch 58, rows @ epoch: 1\n",
      "[0.5023376]\n",
      "epoch 59, rows @ epoch: 1\n",
      "[0.4843617]\n",
      "epoch 60, rows @ epoch: 1\n",
      "[0.49923307]\n",
      "epoch 61, rows @ epoch: 1\n",
      "[0.5167567]\n",
      "epoch 62, rows @ epoch: 1\n",
      "[0.51695764]\n",
      "epoch 63, rows @ epoch: 1\n",
      "[0.50507617]\n",
      "epoch 64, rows @ epoch: 1\n",
      "[0.47272715]\n",
      "epoch 65, rows @ epoch: 1\n",
      "[0.5038843]\n",
      "epoch 66, rows @ epoch: 1\n",
      "[0.51375]\n",
      "epoch 67, rows @ epoch: 1\n",
      "[0.508415]\n",
      "epoch 68, rows @ epoch: 1\n",
      "[0.48850673]\n",
      "epoch 69, rows @ epoch: 1\n",
      "[0.51626146]\n",
      "epoch 70, rows @ epoch: 1\n",
      "[0.46867234]\n",
      "epoch 71, rows @ epoch: 1\n",
      "[0.5429864]\n",
      "epoch 72, rows @ epoch: 1\n",
      "[0.49717277]\n",
      "epoch 73, rows @ epoch: 1\n",
      "[0.49453992]\n",
      "epoch 74, rows @ epoch: 1\n",
      "[0.4931538]\n",
      "epoch 75, rows @ epoch: 1\n",
      "[0.5006081]\n",
      "epoch 76, rows @ epoch: 1\n",
      "[0.47671705]\n",
      "epoch 77, rows @ epoch: 1\n",
      "[0.4994613]\n",
      "epoch 78, rows @ epoch: 1\n",
      "[0.5039215]\n",
      "epoch 79, rows @ epoch: 1\n",
      "[0.5258211]\n",
      "epoch 80, rows @ epoch: 1\n",
      "[0.5014967]\n",
      "epoch 81, rows @ epoch: 1\n",
      "[0.51083446]\n",
      "epoch 82, rows @ epoch: 1\n",
      "[0.496817]\n",
      "epoch 83, rows @ epoch: 1\n",
      "[0.5037739]\n",
      "epoch 84, rows @ epoch: 1\n",
      "[0.5184142]\n",
      "epoch 85, rows @ epoch: 1\n",
      "[0.510268]\n",
      "epoch 86, rows @ epoch: 1\n",
      "[0.4705122]\n",
      "epoch 87, rows @ epoch: 1\n",
      "[0.51695865]\n",
      "epoch 88, rows @ epoch: 1\n",
      "[0.46497345]\n",
      "epoch 89, rows @ epoch: 1\n",
      "[0.5137111]\n",
      "epoch 90, rows @ epoch: 1\n",
      "[0.5114776]\n",
      "epoch 91, rows @ epoch: 1\n",
      "[0.5254322]\n",
      "epoch 92, rows @ epoch: 1\n",
      "[0.51411945]\n",
      "epoch 93, rows @ epoch: 1\n",
      "[0.48474833]\n",
      "epoch 94, rows @ epoch: 1\n",
      "[0.5142839]\n",
      "epoch 95, rows @ epoch: 1\n",
      "[0.4717065]\n",
      "epoch 96, rows @ epoch: 1\n",
      "[0.5244616]\n",
      "epoch 97, rows @ epoch: 1\n",
      "[0.519688]\n",
      "epoch 98, rows @ epoch: 1\n",
      "[0.5227703]\n",
      "epoch 99, rows @ epoch: 1\n",
      "[0.500618]\n",
      "epoch 100, rows @ epoch: 1\n",
      "[0.5244117]\n",
      "epoch 101, rows @ epoch: 1\n",
      "[0.4775255]\n",
      "epoch 102, rows @ epoch: 1\n",
      "[0.49268222]\n",
      "epoch 103, rows @ epoch: 1\n",
      "[0.50505376]\n",
      "epoch 104, rows @ epoch: 1\n",
      "[0.5015872]\n",
      "epoch 105, rows @ epoch: 1\n",
      "[0.50447834]\n",
      "epoch 106, rows @ epoch: 1\n",
      "[0.53387713]\n",
      "epoch 107, rows @ epoch: 1\n",
      "[0.53105414]\n",
      "epoch 108, rows @ epoch: 1\n",
      "[0.48626024]\n",
      "epoch 109, rows @ epoch: 1\n",
      "[0.5080707]\n",
      "epoch 110, rows @ epoch: 1\n",
      "[0.51254606]\n",
      "epoch 111, rows @ epoch: 1\n",
      "[0.4886129]\n",
      "epoch 112, rows @ epoch: 1\n",
      "[0.49719456]\n",
      "epoch 113, rows @ epoch: 1\n",
      "[0.5103918]\n",
      "epoch 114, rows @ epoch: 1\n",
      "[0.509657]\n",
      "epoch 115, rows @ epoch: 1\n",
      "[0.51769984]\n",
      "epoch 116, rows @ epoch: 1\n",
      "[0.48324242]\n",
      "epoch 117, rows @ epoch: 1\n",
      "[0.50349283]\n",
      "epoch 118, rows @ epoch: 1\n",
      "[0.47769096]\n",
      "epoch 119, rows @ epoch: 1\n",
      "[0.47610584]\n",
      "epoch 120, rows @ epoch: 1\n",
      "[0.50277615]\n",
      "epoch 121, rows @ epoch: 1\n",
      "[0.47054014]\n",
      "epoch 122, rows @ epoch: 1\n",
      "[0.5066701]\n",
      "epoch 123, rows @ epoch: 1\n",
      "[0.47307035]\n",
      "epoch 124, rows @ epoch: 1\n",
      "[0.48268455]\n",
      "epoch 125, rows @ epoch: 1\n",
      "[0.54132175]\n",
      "epoch 126, rows @ epoch: 1\n",
      "[0.48472768]\n",
      "epoch 127, rows @ epoch: 1\n",
      "[0.4983511]\n"
     ]
    }
   ],
   "source": [
    "data = next(dataset_loader_test)\n",
    "a = model_clip.get_image_features(pixel_values = data.cuda()).float()\n",
    "a = torch.hstack((a,a))\n",
    "x = a.reshape((-1, 1, 32, 32))\n",
    "countnum = 0\n",
    "test_abnormal_result = []\n",
    "\n",
    "for i in range(128):\n",
    "\n",
    "    predictions = []\n",
    "    sequences = []\n",
    "    mse_thresholds = []\n",
    "\n",
    "    rows, t_distance = 1, 200\n",
    "\n",
    "    threshold = 0.5\n",
    "    print(f\"epoch {i}, rows @ epoch: {rows}\")\n",
    "    for k in range(rows):\n",
    "        countnum += 1\n",
    "        new = next(dataset_loader)\n",
    "        a = model_clip.get_image_features(pixel_values = data.cuda()).float()\n",
    "        a = torch.hstack((a,a))\n",
    "        img = a.reshape((-1, 1, 32, 32))\n",
    "    \n",
    "\n",
    "        #filename = DATASET_PATH + 'final-outputs/ARGS=' + str(args[\"arg_num\"]) + '/abnormal_check/'\n",
    "\n",
    "        output = diff.forward_backward(\n",
    "                unet, img,\n",
    "                see_whole_sequence=\"half\",\n",
    "                # t_distance=5, denoise_fn=args[\"noise_fn\"]\n",
    "                t_distance=t_distance, denoise_fn=args[\"noise_fn\"]\n",
    "                )\n",
    "\n",
    "        loss, estimates = diff.p_loss(unet, img, args, test_t_value = t_distance)\n",
    "        noisy, est = estimates[1], estimates[2]\n",
    "        '''\n",
    "        if new[1].to(device) == 0:\n",
    "            list_norm.append((est - noisy).square()[:1, ...].sum().detach().cpu().numpy())\n",
    "        else:\n",
    "            list_abnorm.append((est - noisy).square()[:1, ...].sum().detach().cpu().numpy())\n",
    "        '''\n",
    "\n",
    "        #output_images = torch.cat((img, output[-1].to(device)))\n",
    "        cos = torch.nn.CosineSimilarity()\n",
    "        result = cos(img.reshape(1,-1), output[-1].reshape(1,-1))\n",
    "        test_abnormal_result.append(result.cpu().detach().numpy())\n",
    "        #predictions.append(\n",
    "        #        output_images\n",
    "        #        )\n",
    "        print(result.cpu().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:33:29.591513554Z",
     "start_time": "2023-10-26T10:28:59.461124509Z"
    }
   },
   "id": "ef5ccabf3ff68a83"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:00:59.222493376Z",
     "start_time": "2023-10-26T10:00:59.172814535Z"
    }
   },
   "id": "4739124a455bb413"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 700x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [np.array(test_normal_result).flatten(), np.array(test_abnormal_result).flatten()]\n",
    "fig = plt.figure(figsize =(7, 5))\n",
    "plt.boxplot(data)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:36:45.591979055Z",
     "start_time": "2023-10-26T10:36:45.434126419Z"
    }
   },
   "id": "fff6ed1d84e079c8"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "data = np.array(test_normal_result + test_abnormal_result).flatten()\n",
    "label = np.array([0]*256)\n",
    "label[:128] = 1\n",
    "data[data >= 0.54 ] = 1\n",
    "data[data < 0.54 ] = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:44:27.105647676Z",
     "start_time": "2023-10-26T10:44:27.064561322Z"
    }
   },
   "id": "53c4aaa26241a362"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import sklearn.metrics as skl"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:45:08.451516289Z",
     "start_time": "2023-10-26T10:45:08.386783040Z"
    }
   },
   "id": "be11be8daf0f83ee"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9344262295081966"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl.f1_score(y_true=label, y_pred=data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T10:45:28.584830561Z",
     "start_time": "2023-10-26T10:45:28.525884273Z"
    }
   },
   "id": "dca620e7eb6e4867"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "87eeb79bf7ac477b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
